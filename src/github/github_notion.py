#!/usr/bin/env python3
"""
GitHubæ´»å‹•ãƒ‡ãƒ¼ã‚¿ï¼ˆIssueã€PRï¼‰ã‚’Notionã®æ—¥è¨˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åŒæœŸã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç’°å¢ƒå¤‰æ•°:
    GITHUB_TOKEN: GitHub Personal Access Tokenï¼ˆrepo ã‚¹ã‚³ãƒ¼ãƒ—ï¼‰
    NOTION_SECRET: Notion Integration ãƒˆãƒ¼ã‚¯ãƒ³
    DATABASE_ID: Notion ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ID
    GCP_PROJECT: Google Cloud ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ IDï¼ˆFirestoreç”¨ï¼‰
"""

import os
import sys
import datetime
import json
import logging
import re
from typing import List, Dict, Optional, Tuple

import requests

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ã«ã™ã‚‹
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’æ‰‹å‹•ã§èª­ã¿è¾¼ã‚€
def load_env_file():
    """
    .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ï¼ˆpython-dotenvã®ä»£æ›¿ï¼‰
    """
    env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), '.env')
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

load_env_file()

# æ—¥æœ¬æ™‚é–“ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = datetime.timezone(datetime.timedelta(hours=9))

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class GitHubNotionSync:
    """GitHubæ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’Notionã«åŒæœŸã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–å‡¦ç†"""
        self.github_token = os.getenv('GITHUB_TOKEN')
        self.notion_token = os.getenv('NOTION_SECRET')
        self.database_id = os.getenv('DATABASE_ID')
        self.gcp_project = os.getenv('GCP_PROJECT')

        if not all([self.github_token, self.notion_token, self.database_id]):
            logger.error("å¿…è¦ãªç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: GITHUB_TOKEN, NOTION_SECRET, DATABASE_ID")
            sys.exit(1)

        # GitHubã®APIãƒ˜ãƒƒãƒ€ãƒ¼
        self.github_headers = {
            "Authorization": f"token {self.github_token}",
            "Accept": "application/vnd.github+json"
        }

        # Notionã®APIãƒ˜ãƒƒãƒ€ãƒ¼
        self.notion_headers = {
            "Authorization": f"Bearer {self.notion_token}",
            "Notion-Version": "2022-06-28",
            "Content-Type": "application/json"
        }

    def parse_date_range(self, arg: str) -> List[datetime.date]:
        """
        æ—¥ä»˜å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’è¿”ã™

        Args:
            arg: "YYYYMMDD" ã¾ãŸã¯ "YYYYMMDD-YYYYMMDD" å½¢å¼ã®æ–‡å­—åˆ—

        Returns:
            æ—¥ä»˜ã®ãƒªã‚¹ãƒˆ
        """
        try:
            if "-" in arg:
                start_str, end_str = arg.split("-", 1)
                start = datetime.datetime.strptime(start_str, "%Y%m%d").date()
                end = datetime.datetime.strptime(end_str, "%Y%m%d").date()
            else:
                start = datetime.datetime.strptime(arg, "%Y%m%d").date()
                end = start

            if end < start:
                raise ValueError("æ—¥ä»˜ç¯„å›²ã®é–‹å§‹ãŒçµ‚äº†ã‚ˆã‚Šå¾Œã§ã™ã€‚")

            dates = []
            current = start
            while current <= end:
                dates.append(current)
                current += datetime.timedelta(days=1)

            return dates
        except Exception as e:
            logger.error(f"æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def get_owned_repos(self) -> List[Dict]:
        """
        è‡ªåˆ†ãŒã‚ªãƒ¼ãƒŠãƒ¼ã®ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’å–å¾—ï¼ˆæœ€æ–°4å€‹ã®ã¿ï¼‰

        Returns:
            ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã®ãƒªã‚¹ãƒˆï¼ˆæ›´æ–°æ—¥æ™‚é †ã€æœ€æ–°4å€‹ï¼‰
        """
        try:
            resp = requests.get(
                "https://api.github.com/user/repos",
                headers=self.github_headers,
                params={
                    "per_page": 4,  # 4å€‹ã«åˆ¶é™ï¼ˆå®Ÿéš›ã®æ´»ç™ºãªãƒªãƒã‚¸ãƒˆãƒªæ•°ã«åˆã‚ã›ã¦æœ€é©åŒ–ï¼‰
                    "page": 1,
                    "affiliation": "owner",
                    "sort": "updated",  # æ›´æ–°æ—¥æ™‚é †
                    "direction": "desc"  # é™é †ï¼ˆæœ€æ–°ãŒå…ˆï¼‰
                }
            )
            resp.raise_for_status()
            repos = resp.json()

            logger.info(f"å–å¾—ã—ãŸãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(repos)} (æœ€æ–°4å€‹ã«åˆ¶é™ã€APIåŠ¹ç‡åŒ–)")
            for repo in repos:
                logger.info(f"  - {repo['full_name']} (updated: {repo['updated_at']})")

            return repos

        except Exception as e:
            logger.error(f"ãƒªãƒã‚¸ãƒˆãƒªå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def fetch_issues_for_date(self, date: datetime.date, repos: List[Dict]) -> List[Dict]:
        """
        æŒ‡å®šæ—¥ï¼ˆJSTï¼‰ã«ã‚¯ãƒ­ãƒ¼ã‚ºã•ã‚ŒãŸIssueã‚’å–å¾—

        Args:
            date: å¯¾è±¡æ—¥ä»˜
            repos: ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§

        Returns:
            Issueæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        # JSTæ™‚é–“ç¯„å›²ã‚’UTCã«å¤‰æ›
        start_jst = datetime.datetime.combine(date, datetime.time(0, 0), tzinfo=JST)
        end_jst = datetime.datetime.combine(date, datetime.time(23, 59, 59, 999999), tzinfo=JST)
        start_utc = start_jst.astimezone(datetime.timezone.utc)
        end_utc = end_jst.astimezone(datetime.timezone.utc)

        items = []

        for repo in repos:
            owner = repo["owner"]["login"]
            name = repo["name"]
            page = 1

            while True:
                try:
                    resp = requests.get(
                        f"https://api.github.com/repos/{owner}/{name}/issues",
                        headers=self.github_headers,
                        params={
                            "state": "closed",
                            "per_page": 100,
                            "page": page,
                            "since": start_utc.isoformat()
                        }
                    )
                    resp.raise_for_status()
                    batch = resp.json()

                    if not batch:
                        break

                    for issue in batch:
                        # PRã§ã¯ãªã„ã“ã¨ã‚’ç¢ºèª
                        if "pull_request" in issue:
                            continue

                        closed_at = issue.get("closed_at")
                        if not closed_at:
                            continue

                        # closed_atã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ™‚é–“ç¯„å›²ã‚’ç¢ºèª
                        closed_dt = datetime.datetime.fromisoformat(closed_at.rstrip("Z")).replace(tzinfo=datetime.timezone.utc)

                        if start_utc <= closed_dt <= end_utc:
                            items.append({
                                "type": "issue",
                                "repo": f"{owner}/{name}",
                                "number": issue["number"],
                                "title": issue["title"],
                                "url": issue["html_url"]
                            })

                    page += 1

                except Exception as e:
                    logger.warning(f"Issueå–å¾—ã‚¹ã‚­ãƒƒãƒ— ({owner}/{name}): {e}")
                    # ã‚¨ãƒ©ãƒ¼ã§ã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªãªã©ï¼‰
                    continue

        logger.info(f"{date} ã®Issueæ•°: {len(items)}")
        return items

    def fetch_prs_for_date(self, date: datetime.date, repos: List[Dict]) -> List[Dict]:
        """
        æŒ‡å®šæ—¥ï¼ˆJSTï¼‰ã«ãƒãƒ¼ã‚¸ã•ã‚ŒãŸPRã‚’å–å¾—

        Args:
            date: å¯¾è±¡æ—¥ä»˜
            repos: ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§

        Returns:
            PRæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        # JSTæ™‚é–“ç¯„å›²ã‚’UTCã«å¤‰æ›
        start_jst = datetime.datetime.combine(date, datetime.time(0, 0), tzinfo=JST)
        end_jst = datetime.datetime.combine(date, datetime.time(23, 59, 59, 999999), tzinfo=JST)
        start_utc = start_jst.astimezone(datetime.timezone.utc)
        end_utc = end_jst.astimezone(datetime.timezone.utc)

        results = []

        for repo in repos:
            owner = repo["owner"]["login"]
            name = repo["name"]

            # ãƒªãƒã‚¸ãƒˆãƒªã®PRã‚’ç›´æ¥å–å¾—ï¼ˆSearch APIã®ä»£æ›¿ï¼‰
            try:
                resp = requests.get(
                    f"https://api.github.com/repos/{owner}/{name}/pulls",
                    headers=self.github_headers,
                    params={
                        "state": "closed",
                        "per_page": 50,  # å„ãƒªãƒã‚¸ãƒˆãƒªæœ€å¤§9550å€‹
                        "sort": "updated",
                        "direction": "desc"
                    }
                )
                resp.raise_for_status()
                prs = resp.json()

                for pr in prs:
                    # ãƒãƒ¼ã‚¸ã•ã‚ŒãŸPRã®ã¿å‡¦ç†
                    if not pr.get("merged_at"):
                        continue

                    # merged_atã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ™‚é–“ç¯„å›²ã‚’ç¢ºèª
                    merged_at = pr["merged_at"]
                    merged_dt = datetime.datetime.fromisoformat(merged_at.rstrip("Z")).replace(tzinfo=datetime.timezone.utc)

                    if start_utc <= merged_dt <= end_utc:
                        results.append({
                            "type": "pr",
                            "repo": f"{owner}/{name}",
                            "number": pr["number"],
                            "title": pr["title"],
                            "url": pr["html_url"]
                        })
                        logger.info(f"  ãƒãƒƒãƒã—ãŸPR: {owner}/{name}#{pr['number']} - {pr['title']}")

            except Exception as e:
                logger.warning(f"PRå–å¾—ã‚¹ã‚­ãƒƒãƒ— ({owner}/{name}): {e}")
                # ã‚¨ãƒ©ãƒ¼ã§ã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªãªã©ï¼‰
                continue

        logger.info(f"{date} ã®PRæ•°: {len(results)}")
        return results

    def fetch_direct_commits_for_date(self, date: datetime.date, repos: List[Dict], pr_commits: set) -> List[Dict]:
        """
        æŒ‡å®šæ—¥ï¼ˆJSTï¼‰ã®mainãƒ–ãƒ©ãƒ³ãƒã¸ã®ç›´æ¥ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—ï¼ˆãƒªãƒã‚¸ãƒˆãƒªã”ã¨ã«é›†è¨ˆï¼‰

        Args:
            date: å¯¾è±¡æ—¥ä»˜
            repos: ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§
            pr_commits: PRã«å«ã¾ã‚Œã‚‹ã‚³ãƒŸãƒƒãƒˆSHAé›†åˆï¼ˆé‡è¤‡é™¤å¤–ç”¨ï¼‰

        Returns:
            ãƒªãƒã‚¸ãƒˆãƒªã”ã¨ã®é›†è¨ˆæƒ…å ±ãƒªã‚¹ãƒˆ
        """
        # JSTæ™‚é–“ç¯„å›²ã‚’ISOå½¢å¼ã«å¤‰æ›
        start_jst = datetime.datetime.combine(date, datetime.time(0, 0), tzinfo=JST)
        end_jst = datetime.datetime.combine(date, datetime.time(23, 59, 59, 999999), tzinfo=JST)

        results = []

        for repo in repos:
            owner = repo["owner"]["login"]
            name = repo["name"]
            repo_key = f"{owner}/{name}"

            try:
                # mainãƒ–ãƒ©ãƒ³ãƒã®ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—
                resp = requests.get(
                    f"https://api.github.com/repos/{owner}/{name}/commits",
                    headers=self.github_headers,
                    params={
                        "sha": repo.get("default_branch", "main"),
                        "since": start_jst.isoformat(),
                        "until": end_jst.isoformat(),
                        "per_page": 100  # å„ãƒªãƒã‚¸ãƒˆãƒªæœ€å¤§100ã‚³ãƒŸãƒƒãƒˆ
                    }
                )
                resp.raise_for_status()
                commits = resp.json()

                # ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ç›´æ¥ã‚³ãƒŸãƒƒãƒˆã‚’é›†è¨ˆ
                total_additions = 0
                total_deletions = 0
                direct_commit_count = 0

                for commit in commits:
                    sha = commit["sha"]

                    # PRã«å«ã¾ã‚Œã‚‹ã‚³ãƒŸãƒƒãƒˆã¯é™¤å¤–
                    if sha in pr_commits:
                        continue

                    # ãƒãƒ¼ã‚¸ã‚³ãƒŸãƒƒãƒˆã‚’é™¤å¤–ï¼ˆè¦ªãŒ2ã¤ä»¥ä¸Šï¼‰
                    if len(commit.get("parents", [])) > 1:
                        continue

                    # ã‚³ãƒŸãƒƒãƒˆè©³ç´°ã‚’å–å¾—ã—ã¦å¤‰æ›´è¡Œæ•°ã‚’ç¢ºèª
                    detail_resp = requests.get(
                        f"https://api.github.com/repos/{owner}/{name}/commits/{sha}",
                        headers=self.github_headers
                    )
                    detail_resp.raise_for_status()
                    detail = detail_resp.json()

                    stats = detail.get("stats", {})
                    total_additions += stats.get("additions", 0)
                    total_deletions += stats.get("deletions", 0)
                    direct_commit_count += 1

                # ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã«ç›´æ¥ã‚³ãƒŸãƒƒãƒˆãŒã‚ã‚Œã°çµæœã«è¿½åŠ 
                if direct_commit_count > 0:
                    results.append({
                        "type": "commit",
                        "repo": repo_key,
                        "commit_count": direct_commit_count,
                        "additions": total_additions,
                        "deletions": total_deletions,
                        "url": f"https://github.com/{repo_key}/commits/{repo.get('default_branch', 'main')}"
                    })
                    logger.info(f"  {repo_key}: {direct_commit_count} commits, +{total_additions}-{total_deletions}")

            except Exception as e:
                logger.warning(f"ã‚³ãƒŸãƒƒãƒˆå–å¾—ã‚¹ã‚­ãƒƒãƒ— ({owner}/{name}): {e}")
                continue

        logger.info(f"{date} ã®ç›´æ¥ã‚³ãƒŸãƒƒãƒˆãŒã‚ã‚‹ãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(results)}")
        return results

    def get_pr_commit_shas(self, prs: List[Dict], repos: List[Dict]) -> set:
        """
        PRã«å«ã¾ã‚Œã‚‹ã‚³ãƒŸãƒƒãƒˆã®SHAã‚’åé›†

        Args:
            prs: PRæƒ…å ±ãƒªã‚¹ãƒˆ
            repos: ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§

        Returns:
            ã‚³ãƒŸãƒƒãƒˆSHAã®ã‚»ãƒƒãƒˆ
        """
        commit_shas = set()

        # ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’è¾æ›¸ã«å¤‰æ›ï¼ˆæ¤œç´¢åŠ¹ç‡åŒ–ï¼‰
        repo_dict = {f"{r['owner']['login']}/{r['name']}": r for r in repos}

        for pr in prs:
            repo_key = pr["repo"]
            pr_number = pr["number"]

            if repo_key not in repo_dict:
                continue

            owner, name = repo_key.split("/")

            try:
                # PRã®ã‚³ãƒŸãƒƒãƒˆä¸€è¦§ã‚’å–å¾—
                resp = requests.get(
                    f"https://api.github.com/repos/{owner}/{name}/pulls/{pr_number}/commits",
                    headers=self.github_headers,
                    params={"per_page": 100}
                )
                resp.raise_for_status()
                commits = resp.json()

                # ã‚³ãƒŸãƒƒãƒˆSHAã‚’åé›†
                for commit in commits:
                    commit_shas.add(commit["sha"])

            except Exception as e:
                logger.warning(f"PRã‚³ãƒŸãƒƒãƒˆå–å¾—ã‚¹ã‚­ãƒƒãƒ— ({repo_key}#{pr_number}): {e}")
                continue

        logger.info(f"PRé–¢é€£ã‚³ãƒŸãƒƒãƒˆæ•°: {len(commit_shas)}")
        return commit_shas

    def build_markdown(self, items: List[Dict]) -> str:
        """
        GitHubæ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’Markdownå½¢å¼ã«æ•´å½¢

        Args:
            items: Issue/PRæƒ…å ±ã®ãƒªã‚¹ãƒˆ

        Returns:
            Markdownå½¢å¼ã®æ–‡å­—åˆ—
        """
        if not items:
            return "- è©²å½“ãªã—"

        lines = []
        for item in items:
            if item["type"] == "issue":
                lines.append(f"- ğŸ« Issue #{item['number']}: [{item['title']}]({item['url']})")
            elif item["type"] == "pr":
                lines.append(f"- ğŸ”€ PR #{item['number']}: [{item['title']}]({item['url']})")
            else:  # commit
                lines.append(f"- ğŸ“ å¤‰æ›´è¡Œæ•°:+{item['additions']}-{item['deletions']} ({item['commit_count']} commits) [{item['repo'].split('/')[1]}]({item['url']})")

        return "\n".join(lines)

    def build_notion_rich_text(self, items: List[Dict]) -> List[Dict]:
        """
        GitHubæ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’Notionã®rich_textå½¢å¼ã«å¤‰æ›

        Args:
            items: Issue/PRæƒ…å ±ã®ãƒªã‚¹ãƒˆ

        Returns:
            Notionã®rich_texté…åˆ—
        """
        if not items:
            return [{"type": "text", "text": {"content": "è©²å½“ãªã—"}}]

        rich_text = []

        for i, item in enumerate(items):
            # ãƒªãƒã‚¸ãƒˆãƒªåã‚’æŠ½å‡ºï¼ˆ"owner/repo" -> "repo"ï¼‰
            repo_name = item["repo"].split("/")[1]

            # å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆãƒªãƒã‚¸ãƒˆãƒªå:Issue/PR #ç•ªå·: ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
            if item["type"] == "issue":
                full_text = f"ğŸ« {repo_name}:Issue #{item['number']}: {item['title']}"
            elif item["type"] == "pr":
                full_text = f"ğŸ”€ {repo_name}:PR #{item['number']}: {item['title']}"
            else:  # commit
                full_text = f"ğŸ“ {repo_name}:å¤‰æ›´è¡Œæ•°:+{item['additions']}-{item['deletions']} ({item['commit_count']} commits)"

            # å…¨ä½“ã‚’ãƒªãƒ³ã‚¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ 
            rich_text.append({
                "type": "text",
                "text": {
                    "content": full_text,
                    "link": {"url": item["url"]}
                }
            })

            # æœ€å¾Œã®ã‚¢ã‚¤ãƒ†ãƒ ä»¥å¤–ã¯æ”¹è¡Œã‚’è¿½åŠ 
            if i < len(items) - 1:
                rich_text.append({
                    "type": "text",
                    "text": {"content": "\n"}
                })

        return rich_text

    def find_notion_page(self, date: datetime.date) -> Optional[Dict]:
        """
        æŒ‡å®šæ—¥ä»˜ã®Notionãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢

        Args:
            date: å¯¾è±¡æ—¥ä»˜

        Returns:
            ãƒšãƒ¼ã‚¸æƒ…å ±ã¾ãŸã¯None
        """
        formatted_date = date.strftime("%Y-%m-%d")

        payload = {
            "filter": {
                "property": "æ—¥ä»˜",
                "date": {"equals": formatted_date}
            },
            "page_size": 1
        }

        try:
            resp = requests.post(
                f"https://api.notion.com/v1/databases/{self.database_id}/query",
                headers=self.notion_headers,
                json=payload
            )
            resp.raise_for_status()
            results = resp.json().get("results", [])

            if not results:
                logger.warning(f"{formatted_date} ã«å¯¾å¿œã™ã‚‹Notionãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None

            return results[0]

        except Exception as e:
            logger.error(f"Notionãƒšãƒ¼ã‚¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def update_notion_page(self, page_id: str, rich_text: List[Dict]) -> Dict:
        """
        Notionãƒšãƒ¼ã‚¸ã®Githubãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ›´æ–°

        Args:
            page_id: ãƒšãƒ¼ã‚¸ID
            rich_text: Notionã®rich_texté…åˆ—

        Returns:
            æ›´æ–°çµæœ
        """
        payload = {
            "properties": {
                "Github": {
                    "rich_text": rich_text
                }
            }
        }

        try:
            resp = requests.patch(
                f"https://api.notion.com/v1/pages/{page_id}",
                headers=self.notion_headers,
                json=payload
            )
            resp.raise_for_status()
            return resp.json()

        except Exception as e:
            logger.error(f"Notionãƒšãƒ¼ã‚¸æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def sync_date(self, date: datetime.date) -> bool:
        """
        æŒ‡å®šæ—¥ä»˜ã®GitHubæ´»å‹•ã‚’Notionã«åŒæœŸ

        Args:
            date: å¯¾è±¡æ—¥ä»˜

        Returns:
            æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        try:
            logger.info(f"å‡¦ç†é–‹å§‹: {date}")

            # ãƒªãƒã‚¸ãƒˆãƒªä¸€è¦§ã‚’1å›ã ã‘å–å¾—ï¼ˆAPIåŠ¹ç‡åŒ–ï¼‰
            repos = self.get_owned_repos()

            # GitHubæ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            issues = self.fetch_issues_for_date(date, repos)
            prs = self.fetch_prs_for_date(date, repos)

            # PRã«å«ã¾ã‚Œã‚‹ã‚³ãƒŸãƒƒãƒˆSHAã‚’åé›†ï¼ˆé‡è¤‡é™¤å¤–ç”¨ï¼‰
            pr_commits = self.get_pr_commit_shas(prs, repos)

            # ç›´æ¥ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—
            direct_commits = self.fetch_direct_commits_for_date(date, repos, pr_commits)

            # å…¨ã‚¢ã‚¤ãƒ†ãƒ ã‚’çµ±åˆ
            all_items = issues + prs + direct_commits

            # ãƒ­ã‚°ç”¨ã®Markdownå½¢å¼ã«æ•´å½¢
            markdown = self.build_markdown(all_items)
            logger.info(f"ç”Ÿæˆã•ã‚ŒãŸMarkdown:\n{markdown}")

            # Notionç”¨ã®rich_textå½¢å¼ã«å¤‰æ›
            rich_text = self.build_notion_rich_text(all_items)
            logger.info(f"Notionãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆè¦ç´ æ•°: {len(rich_text)}")

            # Notionãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢
            page = self.find_notion_page(date)
            if not page:
                logger.warning(f"{date} ã®Notionãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return False

            # Notionãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ï¼ˆãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ï¼‰
            page_id = page["id"]
            self.update_notion_page(page_id, rich_text)
            logger.info(f"âœ… {date} ã®åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆãƒªãƒ³ã‚¯ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ›´æ–°ï¼‰")

            return True

        except Exception as e:
            logger.error(f"âŒ {date} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return False

    def run(self, date_arg: str):
        """
        ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œå‡¦ç†

        Args:
            date_arg: æ—¥ä»˜å¼•æ•°ï¼ˆ"YYYYMMDD" ã¾ãŸã¯ "YYYYMMDD-YYYYMMDD"ï¼‰
        """
        try:
            dates = self.parse_date_range(date_arg)
            success_count = 0

            for date in dates:
                if self.sync_date(date):
                    success_count += 1

            logger.info(f"å‡¦ç†å®Œäº†: {success_count}/{len(dates)} ä»¶æˆåŠŸ")

            if success_count < len(dates):
                sys.exit(1)

        except Exception as e:
            logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ã„æ–¹: python github_notion.py YYYYMMDD ã¾ãŸã¯ YYYYMMDD-YYYYMMDD")
        print("ä¾‹: python github_notion.py 20250731")
        print("ä¾‹: python github_notion.py 20250701-20250731")
        sys.exit(1)

    date_arg = sys.argv[1]
    sync = GitHubNotionSync()
    sync.run(date_arg)


if __name__ == "__main__":
    main()
